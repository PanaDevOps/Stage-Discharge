{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries and functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "url = 'Datasets/2012_2019_PlatteRiverWeir_features_merged_all.csv'\n",
    "\n",
    "dfCNN = pd.read_csv(url)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "            SensorTime          CaptureTime  \\\n0  2012-06-09 13:15:00  2012-06-09T13:09:07   \n1  2012-06-09 13:15:00  2012-06-09T13:10:29   \n2  2012-06-09 13:45:00  2012-06-09T13:44:01   \n3  2012-06-09 14:45:00  2012-06-09T14:44:30   \n4  2012-06-09 15:45:00  2012-06-09T15:44:59   \n\n                                 Filename  Agency   SiteNumber  TimeZone  \\\n0  StateLineWeir_20120609_Farrell_001.jpg    USGS      6674500       MDT   \n1  StateLineWeir_20120609_Farrell_002.jpg    USGS      6674500       MDT   \n2  StateLineWeir_20120609_Farrell_003.jpg    USGS      6674500       MDT   \n3  StateLineWeir_20120609_Farrell_004.jpg    USGS      6674500       MDT   \n4  StateLineWeir_20120609_Farrell_005.jpg    USGS      6674500       MDT   \n\n    Stage   Discharge        CalcTimestamp   width  ...   WeirPt2X   WeirPt2Y  \\\n0    2.99       916.0  2020-03-11T16:58:28    4288  ...         -1         -1   \n1    2.99       916.0  2020-03-11T16:58:33    4288  ...         -1         -1   \n2    2.96       873.0  2020-03-11T16:58:40    4288  ...         -1         -1   \n3    2.94       846.0  2020-03-11T16:58:47    4288  ...         -1         -1   \n4    2.94       846.0  2020-03-11T16:58:55    4288  ...         -1         -1   \n\n    WwRawLineMin   WwRawLineMax   WwRawLineMean   WwRawLineSigma  \\\n0            0.0            0.0             0.0              0.0   \n1            0.0            0.0             0.0              0.0   \n2            0.0            0.0             0.0              0.0   \n3            0.0            0.0             0.0              0.0   \n4            0.0            0.0             0.0              0.0   \n\n    WwCurveLineMin   WwCurveLineMax   WwCurveLineMean   WwCurveLineSigma  \n0              0.0              0.0               0.0                0.0  \n1              0.0              0.0               0.0                0.0  \n2              0.0              0.0               0.0                0.0  \n3              0.0              0.0               0.0                0.0  \n4              0.0              0.0               0.0                0.0  \n\n[5 rows x 59 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SensorTime</th>\n      <th>CaptureTime</th>\n      <th>Filename</th>\n      <th>Agency</th>\n      <th>SiteNumber</th>\n      <th>TimeZone</th>\n      <th>Stage</th>\n      <th>Discharge</th>\n      <th>CalcTimestamp</th>\n      <th>width</th>\n      <th>...</th>\n      <th>WeirPt2X</th>\n      <th>WeirPt2Y</th>\n      <th>WwRawLineMin</th>\n      <th>WwRawLineMax</th>\n      <th>WwRawLineMean</th>\n      <th>WwRawLineSigma</th>\n      <th>WwCurveLineMin</th>\n      <th>WwCurveLineMax</th>\n      <th>WwCurveLineMean</th>\n      <th>WwCurveLineSigma</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2012-06-09 13:15:00</td>\n      <td>2012-06-09T13:09:07</td>\n      <td>StateLineWeir_20120609_Farrell_001.jpg</td>\n      <td>USGS</td>\n      <td>6674500</td>\n      <td>MDT</td>\n      <td>2.99</td>\n      <td>916.0</td>\n      <td>2020-03-11T16:58:28</td>\n      <td>4288</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2012-06-09 13:15:00</td>\n      <td>2012-06-09T13:10:29</td>\n      <td>StateLineWeir_20120609_Farrell_002.jpg</td>\n      <td>USGS</td>\n      <td>6674500</td>\n      <td>MDT</td>\n      <td>2.99</td>\n      <td>916.0</td>\n      <td>2020-03-11T16:58:33</td>\n      <td>4288</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2012-06-09 13:45:00</td>\n      <td>2012-06-09T13:44:01</td>\n      <td>StateLineWeir_20120609_Farrell_003.jpg</td>\n      <td>USGS</td>\n      <td>6674500</td>\n      <td>MDT</td>\n      <td>2.96</td>\n      <td>873.0</td>\n      <td>2020-03-11T16:58:40</td>\n      <td>4288</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2012-06-09 14:45:00</td>\n      <td>2012-06-09T14:44:30</td>\n      <td>StateLineWeir_20120609_Farrell_004.jpg</td>\n      <td>USGS</td>\n      <td>6674500</td>\n      <td>MDT</td>\n      <td>2.94</td>\n      <td>846.0</td>\n      <td>2020-03-11T16:58:47</td>\n      <td>4288</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2012-06-09 15:45:00</td>\n      <td>2012-06-09T15:44:59</td>\n      <td>StateLineWeir_20120609_Farrell_005.jpg</td>\n      <td>USGS</td>\n      <td>6674500</td>\n      <td>MDT</td>\n      <td>2.94</td>\n      <td>846.0</td>\n      <td>2020-03-11T16:58:55</td>\n      <td>4288</td>\n      <td>...</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 59 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfCNN.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "input_path_train = []\n",
    "\n",
    "for filename in os.listdir('train_test_val_images/train'):\n",
    "    for path in os.listdir('train_test_val_images/train/'+filename):\n",
    "        input_path_train.append(os.path.join('train_test_val_images/train', filename, path))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                  images\n0      train_test_val_images/train\\images\\StateLineWe...\n1      train_test_val_images/train\\images\\StateLineWe...\n2      train_test_val_images/train\\images\\StateLineWe...\n3      train_test_val_images/train\\images\\StateLineWe...\n4      train_test_val_images/train\\images\\StateLineWe...\n...                                                  ...\n41854  train_test_val_images/train\\images\\StateLineWe...\n41855  train_test_val_images/train\\images\\StateLineWe...\n41856  train_test_val_images/train\\images\\StateLineWe...\n41857  train_test_val_images/train\\images\\StateLineWe...\n41858  train_test_val_images/train\\images\\StateLineWe...\n\n[41859 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>images</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_test_val_images/train\\images\\StateLineWe...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_test_val_images/train\\images\\StateLineWe...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_test_val_images/train\\images\\StateLineWe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_test_val_images/train\\images\\StateLineWe...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_test_val_images/train\\images\\StateLineWe...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>41854</th>\n      <td>train_test_val_images/train\\images\\StateLineWe...</td>\n    </tr>\n    <tr>\n      <th>41855</th>\n      <td>train_test_val_images/train\\images\\StateLineWe...</td>\n    </tr>\n    <tr>\n      <th>41856</th>\n      <td>train_test_val_images/train\\images\\StateLineWe...</td>\n    </tr>\n    <tr>\n      <th>41857</th>\n      <td>train_test_val_images/train\\images\\StateLineWe...</td>\n    </tr>\n    <tr>\n      <th>41858</th>\n      <td>train_test_val_images/train\\images\\StateLineWe...</td>\n    </tr>\n  </tbody>\n</table>\n<p>41859 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_train['images'] = input_path_train\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "input_path_test = []\n",
    "\n",
    "for filename in os.listdir('train_test_val_images/test'):\n",
    "    for path in os.listdir('train_test_val_images/test/'+filename):\n",
    "        input_path_test.append(os.path.join('train_test_val_images/test', filename, path))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 images\n0     train_test_val_images/test\\images\\StateLineWei...\n1     train_test_val_images/test\\images\\StateLineWei...\n2     train_test_val_images/test\\images\\StateLineWei...\n3     train_test_val_images/test\\images\\StateLineWei...\n4     train_test_val_images/test\\images\\StateLineWei...\n...                                                 ...\n8408  train_test_val_images/test\\images\\StateLineWei...\n8409  train_test_val_images/test\\images\\StateLineWei...\n8410  train_test_val_images/test\\images\\StateLineWei...\n8411  train_test_val_images/test\\images\\StateLineWei...\n8412  train_test_val_images/test\\images\\StateLineWei...\n\n[8413 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>images</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_test_val_images/test\\images\\StateLineWei...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_test_val_images/test\\images\\StateLineWei...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_test_val_images/test\\images\\StateLineWei...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_test_val_images/test\\images\\StateLineWei...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_test_val_images/test\\images\\StateLineWei...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8408</th>\n      <td>train_test_val_images/test\\images\\StateLineWei...</td>\n    </tr>\n    <tr>\n      <th>8409</th>\n      <td>train_test_val_images/test\\images\\StateLineWei...</td>\n    </tr>\n    <tr>\n      <th>8410</th>\n      <td>train_test_val_images/test\\images\\StateLineWei...</td>\n    </tr>\n    <tr>\n      <th>8411</th>\n      <td>train_test_val_images/test\\images\\StateLineWei...</td>\n    </tr>\n    <tr>\n      <th>8412</th>\n      <td>train_test_val_images/test\\images\\StateLineWei...</td>\n    </tr>\n  </tbody>\n</table>\n<p>8413 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame()\n",
    "df_test['images'] = input_path_test\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "df_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "input_path_val = []\n",
    "\n",
    "for filename in os.listdir('train_test_val_images/val'):\n",
    "    for path in os.listdir('train_test_val_images/val/'+filename):\n",
    "        input_path_val.append(os.path.join('train_test_val_images/val', filename, path))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 images\n0     train_test_val_images/val\\images\\StateLineWeir...\n1     train_test_val_images/val\\images\\StateLineWeir...\n2     train_test_val_images/val\\images\\StateLineWeir...\n3     train_test_val_images/val\\images\\StateLineWeir...\n4     train_test_val_images/val\\images\\StateLineWeir...\n...                                                 ...\n8506  train_test_val_images/val\\images\\StateLineWeir...\n8507  train_test_val_images/val\\images\\StateLineWeir...\n8508  train_test_val_images/val\\images\\StateLineWeir...\n8509  train_test_val_images/val\\images\\StateLineWeir...\n8510  train_test_val_images/val\\images\\StateLineWeir...\n\n[8511 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>images</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_test_val_images/val\\images\\StateLineWeir...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_test_val_images/val\\images\\StateLineWeir...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_test_val_images/val\\images\\StateLineWeir...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_test_val_images/val\\images\\StateLineWeir...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_test_val_images/val\\images\\StateLineWeir...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8506</th>\n      <td>train_test_val_images/val\\images\\StateLineWeir...</td>\n    </tr>\n    <tr>\n      <th>8507</th>\n      <td>train_test_val_images/val\\images\\StateLineWeir...</td>\n    </tr>\n    <tr>\n      <th>8508</th>\n      <td>train_test_val_images/val\\images\\StateLineWeir...</td>\n    </tr>\n    <tr>\n      <th>8509</th>\n      <td>train_test_val_images/val\\images\\StateLineWeir...</td>\n    </tr>\n    <tr>\n      <th>8510</th>\n      <td>train_test_val_images/val\\images\\StateLineWeir...</td>\n    </tr>\n  </tbody>\n</table>\n<p>8511 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.DataFrame()\n",
    "df_val['images'] = input_path_val\n",
    "df_val = df_val.sample(frac=1).reset_index(drop=True)\n",
    "df_val"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu',input_shape=(512,512,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', metrics=['accuracy'], loss=\"binary_crossentropy\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 510, 510, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 255, 255, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 253, 253, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 126, 126, 128)    0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 124, 124, 256)     295168    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 62, 62, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 984064)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               503841280 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 504,212,609\n",
      "Trainable params: 504,212,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41859 validated image filenames.\n",
      "Found 8511 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "train_data = datagen.flow_from_dataframe(\n",
    "    df_train,x_col='images',\n",
    "    target_size=(512,512),\n",
    "    batch_size=256,\n",
    "    class_mode='input'\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_dataframe(\n",
    "    df_val,x_col='images',\n",
    "    target_size=(512,512),\n",
    "    batch_size=256,\n",
    "    class_mode='input'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\losses.py\", line 1932, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\backend.py\", line 5247, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, None, None, None)).\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [28], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit(train_data, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, validation_data\u001B[38;5;241m=\u001B[39mval_data)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m---> 67\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     69\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\workspace\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1145\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[0;32m   1146\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m-> 1147\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mag_error_metadata\u001B[38;5;241m.\u001B[39mto_exception(e)\n\u001B[0;32m   1148\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1149\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\losses.py\", line 1932, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"C:\\Users\\alex_\\anaconda3\\envs\\workspace\\lib\\site-packages\\keras\\backend.py\", line 5247, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, None, None, None)).\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, epochs=5, validation_data=val_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
